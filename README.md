# Text Classification papers

This repository contains resources for Natural Language Processing (NLP) with a focus on the task of Text Classification.

# Table of Contents

<details>

<summary><b>Expand Table of Contents</b></summary><blockquote><p align="justify">

- [Surveys](#Surveys)
- [Shallow Learning Models](#Shallow Learning Models)
- [Deep Learning models](#Deep Learning models)
- [Datasets](#Datasets)
- [Tools and Repos](#tools-and-repos)
</p></blockquote></details>

---


## Surveys


### 2020


<details>
<summary>1. <a href="https://arxiv.org/pdf/2008.00364.pdf">A Survey on Text Classification: From Shallow to Deep Learning</a> by<i> Qian Li, Hao Peng, Jianxin Li, Congying Xia, Renyu Yang, Lichao Sun, Philip S. Yu, Lifang He
</i></summary><blockquote><p align="justify">
Text classification is the most fundamental and essential task in natural language processing. The last decade has seen a surge of research in this area due to the unprecedented success of deep learning. Numerous methods, datasets, and evaluation metrics have been proposed in the literature, raising the need for a comprehensive and updated survey. This paper fills the gap by reviewing the state of the art approaches from 1961 to 2020, focusing on models from shallow to deep learning. We create a taxonomy for text classification according to the text involved and the models used for feature extraction and classification. We then discuss each of these categories in detail, dealing with both the technical developments and benchmark datasets that support tests of predictions. A comprehensive comparison between different techniques, as well as identifying the pros and cons of various evaluation metrics are also provided in this survey. Finally, we conclude by summarizing key implications, future research directions, and the challenges facing the research area.
</p></blockquote></details>

### 2019


<details>
<summary>1. <a href="https://arxiv.org/pdf/1904.08067.pdf">Text Classification Algorithms: A Survey</a> by<i> Kamran Kowsari, Kiana Jafari Meimandi, Mojtaba Heidarysafa, Sanjana Mendu, Laura E. Barnes, Donald E. Brown 
</i></summary><blockquote><p align="justify">
In recent years, there has been an exponential growth in the number of complex documents and texts that require a deeper understanding of machine learning methods to be able to accurately classify texts in many applications. Many machine learning approaches have achieved surpassing results in natural language processing. The success of these learning algorithms relies on their capacity to understand complex models and non-linear relationships within data. However, finding suitable structures, architectures, and techniques for text classification is a challenge for researchers. In this paper, a brief overview of text classification algorithms is discussed. This overview covers different text feature extractions, dimensionality reduction methods, existing algorithms and techniques, and evaluations methods. Finally, the limitations of each technique and their application in the real-world problem are discussed.
</p></blockquote></details>



<details>
<summary>2. <a href="https://arxiv.org/pdf/2004.03705.pdf">Deep Learning Based Text Classification: A Comprehensive Review</a> by<i> Shervin Minaee, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam Chenaghlu, Jianfeng Gao </i></summary><blockquote><p align="justify">
Deep learning based models have surpassed classical machine learning based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this work, we provide a detailed review of more than 150 deep learning based models for text classification developed in recent years, and discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and discuss future research directions.
</p></blockquote></details>



## Shallow Learning Models
[:arrow_up:](#table-of-contents)
### 1961 

<details>
<summary>1. <a href="https://dl.acm.org/doi/10.1145/321075.321084">Na√Øve Bayes (NB)</a> (<a href="https://github.com/Gunjitbedi/Text-Classification">{Github}</a>) </summary><blockquote><p align="justify">
</p></blockquote></details>


## Deep learning Models
[:arrow_up:](#table-of-contents)
### 2014



<details>
<summary>1. <a href="https://www.aclweb.org/anthology/D14-1181.pdf">Convolutional Neural Networks for Sentence Classification</a> TextCNN (<a href="https://github.com/alexander-rakhlin/CNN-for-Sentence-Classification-in-Keras">Github</a>)</summary><blockquote><p align="justify">
</p></blockquote></details>



## Data
[:arrow_up:](#table-of-contents)

* <a href="https://www-nlpir.nist.gov/related_projects/muc/muc_data/muc_data_index.html">MUC Data Sets</a>
* Automatic Content Extraction (ACE) 
	* <a href="https://www.ldc.upenn.edu/collaborations/past-projects/ace">Program</a>
	* <a href="https://catalog.ldc.upenn.edu/LDC2003T11">ACE-2 corpus</a>
	* <a href="https://catalog.ldc.upenn.edu/LDC2006T06">ACE 05 corpus</a>
* Light & Rich ERE
	* <a href="http://www.aclweb.org/old_anthology/W/W15/W15-0812.pdf">Paper</a> 
* <a href="http://www.newsreader-project.eu/results/data/the-ecb-corpus/">The ECB+ Corpus</a>
* <a href="http://www.newsreader-project.eu/results/data/wikinews/">The NewsReader MEANTIME corpus</a>
* <a href="https://tac.nist.gov//2015/KBP/Event/index.html">TAC KBP 2015 Event Track</a>
* <a href="https://tac.nist.gov/">Text Analysis Conference</a>
* <a href="https://framenet.icsi.berkeley.edu/fndrupal/">FrameNet</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2013T19">OntoNotes Release 5.0</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2008T23">NomBank v 1.0</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2004T14">Proposition Bank I</a>
* <a href="https://catalog.ldc.upenn.edu/LDC99T42">Treebank-3</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2014T12">Abstract Meaning Representation (AMR) Annotation Release 1.0</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2006T08">TimeBank 1.2</a>
* <a href="http://universal.elra.info/product_info.php?cPath=42_43&products_id=2333">AQUAINT TimeML</a>  ( <a href="https://github.com/cnorthwood/ternip/tree/master/sample_data/aquaint_timeml_1.0">data</a> )
* <a href="https://www.cs.york.ac.uk/semeval-2013/task1/index.html">TempEval-3</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2009T23">FactBank 1.0</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2011T08">Datasets for Generic Relation Extraction (reACE)</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2016T23">Richer Event Description</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2005T16">TDT4 Multilingual Text and Annotations</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2017T09">The EventStatus Corpus</a>
* <a href="https://catalog.ldc.upenn.edu/LDC2009T10">Language Understanding Annotation Corpus</a>
* <a href="http://nactem.ac.uk/MLEE/">Multi-Level Event Extraction </a>
* <a href="https://osf.io/enu2k/">SentiFM company-specific economic news event dataset (English)</a>

## Tools and Repos



<details>
<summary><a href="https://github.com/ahsi/Multilingual_Event_Extraction">CMU Multilingual Event Extractor</a></summary><blockquote><p align="justify">
Python code to run ACE-style event extraction on English, Chinese, or Spanish texts 
</p></blockquote></details>
